Databases Project

Partners:
Louie DiBernardo (LDIBERN1)
Sanddhya Jayabalan (SJAYABA1)

Full zip download link:
https://livejohnshopkins-my.sharepoint.com/:u:/g/personal/ldibern1_jh_edu/EYvp8JxlwNRAgDsZ5SDeteQBd9dHB8XfQF4ZggIKyYDlEQ?e=JdoONL

CONCERNS/WRAP-UP:
We have gone into more depth about these concerns/issues in our process.txt files. We had some trouble
finding all the original data we hoped for. For example, we could not find breakdowns of crime rate or
literacy rate by location. We also had some trouble finding some average household stats like the number of
dependents, number enrolled in school, etc by location but we tried to get as much average household
data as we could at the federal level by year to try to make some interesting correlations in this
area. Finally, we had to cut down on some of the Food/Consumption/Nutrition/Distribution relations (described
in process.txt) because the consumption data we were able to find was pretty general and not broken
down into speicfic food groups as we had originally hoped. We were also only able to find detailed
consumption data for California so when writing queries with this relation we will keep this in mind.

Aside from finding the data we had another issue with loading our full datasets into dbase. Some of
our largest datasets contain ~32000 and ~212000 tuples (for the Location and MetabolicDisease relations,
repsectively). Louie has a local instance of MariaDB running on his computer and we were able to
successfully use the setup.sql script to load all the data without any error. However, we had an issue
with loading more than 32000 tuples into the dbase database so when we tried to run our setup.sql
script with the original datafiles it would throw an error which we found online to be due to a
32000 tuple-limit in the database. We did not have enough time to resolve this issue during this phase
but we have ideas for how to resolve this issue before next phase. Namely, we are going to write a
script that will parse through all the scripts that have LocationID as a foreign key constraing with
respect to the Location relation to find all the location IDs in the locatio relation that are
actually referenced. The location relation contains every single city/county/state in the US so
it contains over 32000 entries. We are hoping that by pruning it to only contain referenced
locations this will significantly cut down the size. Out MetabolicDisease relation data file
is also extremely large (~212000 tuples). To make this file smaller we plan on consolidating
the data by location (by performing an average across each county). We will first try to consolidate
at the county level, but if there are still too many tuples, we may have to consolidate to the
state level.

HOW TO RUN THIS REPO:
Log into ugradx and put this entire repo into your home folder. cd into the DatabasesProject folder.
run your login script to log into your dbase account. Select your database using:
USE [name of your database].

Now you can run: source ~/DatabasesProject/sql/production/cleanup.sql;
This will remove any existing tables with the same name.

Then run: source ~/DatabasesProject/sql/production/setup-small.sql;
This will create all the tables and populate them with the small data. This data is in the exact same
format as the full data, but is parred down to just california locations.

To run the full script run: source ~/DatabasesProject/sql/production/setup.sql;
This contains all data we have gathered. Sadly, this will fail in dbase due to user account restrictions.
If you run these scripts on a local mariadb instance using the root account, all the scripts will work,
and all data will be populated. We explain further in the section about this.

If you do plan to run the full script on your local machine, you'll need to adjust the paths in the setup
sql scripts for the data files to be their absolute paths in your system. An example of this is commented
at the bottom of the full setup file. You'll also need to use the correct path for the script files when
you run them. We used an IDE to run our scripts so we didnt need to use cli to run them.

WHERE TO FIND FILES:
Full data files can be found under: /DatabasesProject/data/final/

Small data files can be found under: /DatabasesProject/data/final-small/

SQL scripts can be found under: /DatabasesProject/sql/production/

Phase C documents can be found under: /DatabasesProject/docs/PhaseC/
These include the process.txt file, and a couple extra files we used for planning you can see as well.
